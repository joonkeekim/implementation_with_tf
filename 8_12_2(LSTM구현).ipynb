{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"name":"8_12_2(LSTM구현).ipynb","provenance":[],"collapsed_sections":[],"authorship_tag":"ABX9TyMf0sT5IJA3kvdZdPHPhxvh"},"kernelspec":{"name":"python3","display_name":"Python 3"}},"cells":[{"cell_type":"code","metadata":{"id":"NjCA9MNr3XHO","colab_type":"code","colab":{},"executionInfo":{"status":"ok","timestamp":1597240310202,"user_tz":-540,"elapsed":1039,"user":{"displayName":"김준기","photoUrl":"","userId":"08456149661061922976"}}},"source":["import tensorflow as tf\n","\n","EPOCHS = 10\n","NUM_WORDS = 10000"],"execution_count":7,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"J3uGiBIe30ZB","colab_type":"text"},"source":["#모델 정의"]},{"cell_type":"code","metadata":{"id":"37vK-_B83njx","colab_type":"code","colab":{},"executionInfo":{"status":"ok","timestamp":1597240310202,"user_tz":-540,"elapsed":1034,"user":{"displayName":"김준기","photoUrl":"","userId":"08456149661061922976"}}},"source":["class RNN(tf.keras.Model):\n","    def __init__(self):\n","        super(RNN,self).__init__()\n","        #단어를 one hot vector로 표현할거임 실수로 embedding을 사용해서 길이가 16인 feature 벡터로 바꿔줌\n","        self.emb = tf.keras.layers.Embedding(NUM_WORDS, 16)\n","        self.rnn = tf.keras.layers.LSTM(32)#적어 적어~~\n","        self.dense = tf.keras.layers.Dense(2,activation='softmax')#imdb set 쓸건데, 영화 리뷰가 있고, 긍정적이냐 부정적이냐로 함\n","        \n","    def __call__(self,x,training = False,mask = None):\n","        x=self.emb(x)\n","        x=self.rnn(x)\n","        return self.dense(x)"],"execution_count":8,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"3Alaryph32cM","colab_type":"text"},"source":["#루프 정의"]},{"cell_type":"code","metadata":{"id":"5nlpf9tJ3nvS","colab_type":"code","colab":{},"executionInfo":{"status":"ok","timestamp":1597240310203,"user_tz":-540,"elapsed":1030,"user":{"displayName":"김준기","photoUrl":"","userId":"08456149661061922976"}}},"source":["@tf.function\n","def train_step(model,inputs,labels,loss_object,optimizer,train_loss,train_accuracy):\n","  with tf.GradientTape() as tape:\n","    predictions = model(inputs,training = True)\n","    loss = loss_object(labels, predictions)\n","  gradients = tape.gradient(loss, model.trainable_variables)\n","\n","  optimizer.apply_gradients(zip(gradients,model.trainable_variables))\n","  train_loss(loss)\n","  train_accuracy(labels,predictions)\n","  \n","@tf.function\n","def test_step(model,inputs,labels,loss_object,test_loss,test_accuracy):\n","  predictions = model(inputs, training = False)\n","\n","  t_loss = loss_object(labels,predictions)\n","  test_loss(t_loss)\n","  test_accuracy(labels,predictions)"],"execution_count":9,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"tTMSLb6837y0","colab_type":"text"},"source":["#데이터셋"]},{"cell_type":"code","metadata":{"id":"xN-q3ERM3n1X","colab_type":"code","colab":{},"executionInfo":{"status":"ok","timestamp":1597240316860,"user_tz":-540,"elapsed":7683,"user":{"displayName":"김준기","photoUrl":"","userId":"08456149661061922976"}}},"source":["imdb = tf.keras.datasets.imdb\n","(x_train,y_train),(x_test,y_test) = imdb.load_data(num_words = NUM_WORDS)\n","\n","#길이 맞춰서 앞에 padding으로 0을 넣어준다.\n","x_train = tf.keras.preprocessing.sequence.pad_sequences(x_train,\n","                                                        value=0,\n","                                                        padding='pre',\n","                                                        maxlen=32)\n","x_test = tf.keras.preprocessing.sequence.pad_sequences(x_test,\n","                                                        value=0,\n","                                                        padding='pre',\n","                                                        maxlen=32)\n","\n","train_ds = tf.data.Dataset.from_tensor_slices((x_train,y_train)).shuffle(10000).batch(32)\n","test_ds = tf.data.Dataset.from_tensor_slices((x_test,y_test)).batch(32) "],"execution_count":10,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"0oPNBWY439hY","colab_type":"text"},"source":["#학습 환경 정의"]},{"cell_type":"code","metadata":{"id":"0YVzwboN3n7n","colab_type":"code","colab":{},"executionInfo":{"status":"ok","timestamp":1597240316863,"user_tz":-540,"elapsed":7681,"user":{"displayName":"김준기","photoUrl":"","userId":"08456149661061922976"}}},"source":["model = RNN()\n","\n","loss_object = tf.keras.losses.SparseCategoricalCrossentropy()\n","optimizer = tf.keras.optimizers.Adam()\n","\n","train_loss = tf.keras.metrics.Mean(name = 'train_loss')\n","train_accuracy = tf.keras.metrics.SparseCategoricalAccuracy(name = 'train_accuracy')\n","\n","test_loss = tf.keras.metrics.Mean(name = 'test_loss')\n","test_accuracy = tf.keras.metrics.SparseCategoricalAccuracy(name = 'test_accuracy')"],"execution_count":11,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"wAUIDzum4KlF","colab_type":"text"},"source":["#학습"]},{"cell_type":"code","metadata":{"id":"h0rPuDIL3oAg","colab_type":"code","colab":{"base_uri":"https://localhost:8080/","height":187},"executionInfo":{"status":"ok","timestamp":1597240434833,"user_tz":-540,"elapsed":125647,"user":{"displayName":"김준기","photoUrl":"","userId":"08456149661061922976"}},"outputId":"446978d1-0b4c-4510-f5e7-2f40ec263019"},"source":["for epoch in range(EPOCHS):\n","  for seqs,labels in train_ds:\n","    train_step(model, seqs, labels, loss_object, optimizer, train_loss, train_accuracy)\n","\n","  for test_seqs, test_labels in test_ds:\n","    test_step(model, test_seqs, test_labels, loss_object, test_loss, test_accuracy)\n","\n","  template = 'Epoch:{}, Loss: {}, Accuracy: {}, Test Loss: {}, Test Accuracy: {}'\n","  print(template.format(epoch+1,\n","                        train_loss.result(),\n","                        train_accuracy.result()*100,\n","                        test_loss.result(),\n","                        test_accuracy.result()*100))\n","  train_loss.reset_states()\n","  train_accuracy.reset_states()\n","  test_loss.reset_states()\n","  test_accuracy.reset_states()"],"execution_count":12,"outputs":[{"output_type":"stream","text":["Epoch:1, Loss: 0.5010381937026978, Accuracy: 74.43600463867188, Test Loss: 0.44217270612716675, Test Accuracy: 78.81999969482422\n","Epoch:2, Loss: 0.36999449133872986, Accuracy: 83.42400360107422, Test Loss: 0.45302993059158325, Test Accuracy: 78.85199737548828\n","Epoch:3, Loss: 0.312820166349411, Accuracy: 86.59200286865234, Test Loss: 0.46954014897346497, Test Accuracy: 78.46800231933594\n","Epoch:4, Loss: 0.2569601833820343, Accuracy: 89.3479995727539, Test Loss: 0.521030604839325, Test Accuracy: 77.54399871826172\n","Epoch:5, Loss: 0.20566490292549133, Accuracy: 91.74800109863281, Test Loss: 0.5926687717437744, Test Accuracy: 77.02400207519531\n","Epoch:6, Loss: 0.15837830305099487, Accuracy: 93.7760009765625, Test Loss: 0.7286831140518188, Test Accuracy: 75.40399932861328\n","Epoch:7, Loss: 0.12113245576620102, Accuracy: 95.48799896240234, Test Loss: 0.7515762448310852, Test Accuracy: 75.43199920654297\n","Epoch:8, Loss: 0.09578651934862137, Accuracy: 96.46400451660156, Test Loss: 0.9483672976493835, Test Accuracy: 74.3239974975586\n","Epoch:9, Loss: 0.07212059944868088, Accuracy: 97.39999389648438, Test Loss: 1.2360942363739014, Test Accuracy: 74.7560043334961\n","Epoch:10, Loss: 0.05745380371809006, Accuracy: 97.96400451660156, Test Loss: 1.1288654804229736, Test Accuracy: 75.05999755859375\n"],"name":"stdout"}]}]}