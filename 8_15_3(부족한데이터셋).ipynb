{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"name":"8_15_3(부족한데이터셋).ipynb","provenance":[],"collapsed_sections":[],"authorship_tag":"ABX9TyPYHiCt/LvxorBo5olUJFGW"},"kernelspec":{"name":"python3","display_name":"Python 3"},"accelerator":"GPU"},"cells":[{"cell_type":"code","metadata":{"id":"FiZhq3EMPlh8","colab_type":"code","colab":{},"executionInfo":{"status":"ok","timestamp":1597499440248,"user_tz":-540,"elapsed":2617,"user":{"displayName":"김준기","photoUrl":"","userId":"08456149661061922976"}}},"source":["import tensorflow as tf\n","import numpy as np\n","import random"],"execution_count":1,"outputs":[]},{"cell_type":"code","metadata":{"id":"BMxp2GS4SdFd","colab_type":"code","colab":{},"executionInfo":{"status":"ok","timestamp":1597499440249,"user_tz":-540,"elapsed":2611,"user":{"displayName":"김준기","photoUrl":"","userId":"08456149661061922976"}}},"source":["EPOCHS = 100"],"execution_count":2,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"kl8aMVpaTJq9","colab_type":"text"},"source":["#모델 정의"]},{"cell_type":"code","metadata":{"id":"oHhy0D5WSeys","colab_type":"code","colab":{},"executionInfo":{"status":"ok","timestamp":1597499440250,"user_tz":-540,"elapsed":2608,"user":{"displayName":"김준기","photoUrl":"","userId":"08456149661061922976"}}},"source":["class MyModel(tf.keras.Model):\n","    def __init__(self):\n","        super(MyModel,self).__init__()\n","        self.flatten = tf.keras.layers.Flatten()\n","        self.dense1 = tf.keras.layers.Dense(1024,activation='relu')\n","        self.dense2 = tf.keras.layers.Dense(1,activation = 'sigmoid')\n","\n","    def __call__(self,x,training = False,mask = None):\n","        x = self.flatten(x)\n","        x = self.dense1(x)\n","        return self.dense2(x)"],"execution_count":3,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"RJKppJS3TIBn","colab_type":"text"},"source":["#데이터셋(불균형한 데이터셋으로 만듬)"]},{"cell_type":"code","metadata":{"id":"eBeffR-vTO8z","colab_type":"code","colab":{"base_uri":"https://localhost:8080/","height":51},"executionInfo":{"status":"ok","timestamp":1597499450960,"user_tz":-540,"elapsed":13314,"user":{"displayName":"김준기","photoUrl":"","userId":"08456149661061922976"}},"outputId":"ededa5ec-1c3e-4782-bf2d-acdd185041a6"},"source":["cifar = tf.keras.datasets.cifar10\n","\n","(x_train,y_train),(x_test,y_test) = cifar.load_data()\n","x_train, x_test = x_train/255.0,x_test/255.0\n","\n","x_train_small = list()\n","y_train_small = list()\n","for x,y in zip(x_train,y_train):\n","    if (y == 0 and random.randint(0,100)<10) or y == 1:#0번 10퍼센트만 사용 1번 전부 나머진 ㄴㄴ\n","        x_train_small.append(x[:])#미리 flatten\n","        y_train_small.append(y)\n","\n","x_test_small = list()\n","y_test_small = list()\n","for x,y in zip(x_test,y_test):\n","    if (y == 0 or y == 1):#0번 10퍼센트만 사용 1번 전부 나머진 ㄴㄴ\n","        x_test_small.append(x[:])#미리 flatten\n","        y_test_small.append(y)\n","\n","x_train = np.stack(x_train_small, axis = 0)\n","y_train = np.stack(y_train_small, axis = 0)\n"," \n","x_test = np.stack(x_test_small, axis = 0)\n","y_test = np.stack(y_test_small, axis = 0)\n","\n","train_ds = tf.data.Dataset.from_tensor_slices((x_train,y_train)).shuffle(10000).batch(32).prefetch(2048)\n","test_ds = tf.data.Dataset.from_tensor_slices((x_test,y_test)).batch(32).prefetch(2048)\n"],"execution_count":4,"outputs":[{"output_type":"stream","text":["Downloading data from https://www.cs.toronto.edu/~kriz/cifar-10-python.tar.gz\n","170500096/170498071 [==============================] - 2s 0us/step\n"],"name":"stdout"}]},{"cell_type":"markdown","metadata":{"id":"Wim-bndbXTls","colab_type":"text"},"source":["#Keras API 모델 학습(불균형한 데이터셋)"]},{"cell_type":"code","metadata":{"id":"qBS0mi8DXYOs","colab_type":"code","colab":{"base_uri":"https://localhost:8080/","height":1000},"executionInfo":{"status":"ok","timestamp":1597499620609,"user_tz":-540,"elapsed":182956,"user":{"displayName":"김준기","photoUrl":"","userId":"08456149661061922976"}},"outputId":"a3669abd-7583-4956-a7c3-33e5488a0f14"},"source":["model = MyModel()\n","model.compile(optimizer='adam',\n","              loss='binary_crossentropy',\n","              metrics=['accuracy',\n","                       tf.keras.metrics.Precision(name='precision'),#shallow nn 이라 좀 보조해줄거\n","                       tf.keras.metrics.Recall(name='recall')])\n","model.fit(train_ds, validation_data = test_ds, epochs = EPOCHS)\n","#loss 존나 안낮아짐."],"execution_count":5,"outputs":[{"output_type":"stream","text":["Epoch 1/100\n","WARNING:tensorflow:Layer flatten is casting an input tensor from dtype float64 to the layer's dtype of float32, which is new behavior in TensorFlow 2.  The layer has dtype float32 because its dtype defaults to floatx.\n","\n","If you intended to run this layer in float32, you can safely ignore this warning. If in doubt, this warning is likely only an issue if you are porting a TensorFlow 1.X model to TensorFlow 2.\n","\n","To change all layers to have dtype float64 by default, call `tf.keras.backend.set_floatx('float64')`. To change just this layer, pass dtype='float64' to the layer constructor. If you are the author of this layer, you can disable autocasting by passing autocast=False to the base Layer constructor.\n","\n","172/172 [==============================] - 2s 11ms/step - loss: 0.4241 - accuracy: 0.9063 - precision: 0.9246 - recall: 0.9768 - val_loss: 1.0191 - val_accuracy: 0.5575 - val_precision: 0.5308 - val_recall: 0.9910\n","Epoch 2/100\n","172/172 [==============================] - 2s 9ms/step - loss: 0.2403 - accuracy: 0.9202 - precision: 0.9325 - recall: 0.9836 - val_loss: 1.2252 - val_accuracy: 0.5425 - val_precision: 0.5223 - val_recall: 0.9950\n","Epoch 3/100\n","172/172 [==============================] - 2s 9ms/step - loss: 0.2260 - accuracy: 0.9231 - precision: 0.9388 - recall: 0.9794 - val_loss: 1.1990 - val_accuracy: 0.5605 - val_precision: 0.5324 - val_recall: 0.9930\n","Epoch 4/100\n","172/172 [==============================] - 2s 9ms/step - loss: 0.2132 - accuracy: 0.9253 - precision: 0.9395 - recall: 0.9812 - val_loss: 0.5838 - val_accuracy: 0.7365 - val_precision: 0.6610 - val_recall: 0.9710\n","Epoch 5/100\n","172/172 [==============================] - 2s 9ms/step - loss: 0.2072 - accuracy: 0.9291 - precision: 0.9424 - recall: 0.9822 - val_loss: 0.6958 - val_accuracy: 0.6915 - val_precision: 0.6219 - val_recall: 0.9770\n","Epoch 6/100\n","172/172 [==============================] - 2s 9ms/step - loss: 0.1964 - accuracy: 0.9306 - precision: 0.9434 - recall: 0.9828 - val_loss: 0.4671 - val_accuracy: 0.7965 - val_precision: 0.7322 - val_recall: 0.9350\n","Epoch 7/100\n","172/172 [==============================] - 2s 9ms/step - loss: 0.1965 - accuracy: 0.9291 - precision: 0.9433 - recall: 0.9812 - val_loss: 0.9684 - val_accuracy: 0.6110 - val_precision: 0.5629 - val_recall: 0.9930\n","Epoch 8/100\n","172/172 [==============================] - 2s 9ms/step - loss: 0.1754 - accuracy: 0.9378 - precision: 0.9488 - recall: 0.9850 - val_loss: 0.8071 - val_accuracy: 0.6735 - val_precision: 0.6068 - val_recall: 0.9860\n","Epoch 9/100\n","172/172 [==============================] - 2s 9ms/step - loss: 0.1765 - accuracy: 0.9386 - precision: 0.9502 - recall: 0.9842 - val_loss: 0.5755 - val_accuracy: 0.7585 - val_precision: 0.6801 - val_recall: 0.9760\n","Epoch 10/100\n","172/172 [==============================] - 2s 9ms/step - loss: 0.1933 - accuracy: 0.9318 - precision: 0.9464 - recall: 0.9808 - val_loss: 0.5545 - val_accuracy: 0.7585 - val_precision: 0.6801 - val_recall: 0.9760\n","Epoch 11/100\n","172/172 [==============================] - 2s 9ms/step - loss: 0.1705 - accuracy: 0.9382 - precision: 0.9505 - recall: 0.9834 - val_loss: 0.5174 - val_accuracy: 0.7930 - val_precision: 0.7183 - val_recall: 0.9640\n","Epoch 12/100\n","172/172 [==============================] - 2s 9ms/step - loss: 0.1647 - accuracy: 0.9391 - precision: 0.9520 - recall: 0.9828 - val_loss: 0.7345 - val_accuracy: 0.6940 - val_precision: 0.6219 - val_recall: 0.9900\n","Epoch 13/100\n","172/172 [==============================] - 2s 9ms/step - loss: 0.1529 - accuracy: 0.9464 - precision: 0.9551 - recall: 0.9876 - val_loss: 0.5715 - val_accuracy: 0.7690 - val_precision: 0.6911 - val_recall: 0.9730\n","Epoch 14/100\n","172/172 [==============================] - 2s 9ms/step - loss: 0.1503 - accuracy: 0.9450 - precision: 0.9566 - recall: 0.9842 - val_loss: 0.4761 - val_accuracy: 0.8135 - val_precision: 0.7451 - val_recall: 0.9530\n","Epoch 15/100\n","172/172 [==============================] - 2s 9ms/step - loss: 0.1510 - accuracy: 0.9459 - precision: 0.9578 - recall: 0.9840 - val_loss: 0.9856 - val_accuracy: 0.6500 - val_precision: 0.5893 - val_recall: 0.9900\n","Epoch 16/100\n","172/172 [==============================] - 2s 9ms/step - loss: 0.1396 - accuracy: 0.9486 - precision: 0.9591 - recall: 0.9856 - val_loss: 0.6879 - val_accuracy: 0.7360 - val_precision: 0.6599 - val_recall: 0.9740\n","Epoch 17/100\n","172/172 [==============================] - 2s 9ms/step - loss: 0.1453 - accuracy: 0.9477 - precision: 0.9584 - recall: 0.9854 - val_loss: 0.4740 - val_accuracy: 0.8165 - val_precision: 0.7478 - val_recall: 0.9550\n","Epoch 18/100\n","172/172 [==============================] - 2s 9ms/step - loss: 0.1339 - accuracy: 0.9488 - precision: 0.9607 - recall: 0.9840 - val_loss: 0.6767 - val_accuracy: 0.7505 - val_precision: 0.6715 - val_recall: 0.9810\n","Epoch 19/100\n","172/172 [==============================] - 2s 9ms/step - loss: 0.1268 - accuracy: 0.9511 - precision: 0.9617 - recall: 0.9856 - val_loss: 1.0030 - val_accuracy: 0.6620 - val_precision: 0.5975 - val_recall: 0.9930\n","Epoch 20/100\n","172/172 [==============================] - 2s 9ms/step - loss: 0.1268 - accuracy: 0.9550 - precision: 0.9666 - recall: 0.9846 - val_loss: 0.6344 - val_accuracy: 0.7670 - val_precision: 0.6859 - val_recall: 0.9850\n","Epoch 21/100\n","172/172 [==============================] - 2s 9ms/step - loss: 0.1274 - accuracy: 0.9522 - precision: 0.9636 - recall: 0.9848 - val_loss: 0.6747 - val_accuracy: 0.7615 - val_precision: 0.6807 - val_recall: 0.9850\n","Epoch 22/100\n","172/172 [==============================] - 2s 9ms/step - loss: 0.1190 - accuracy: 0.9566 - precision: 0.9659 - recall: 0.9872 - val_loss: 0.9448 - val_accuracy: 0.6995 - val_precision: 0.6270 - val_recall: 0.9850\n","Epoch 23/100\n","172/172 [==============================] - 2s 9ms/step - loss: 0.1279 - accuracy: 0.9526 - precision: 0.9631 - recall: 0.9858 - val_loss: 0.5440 - val_accuracy: 0.8070 - val_precision: 0.7308 - val_recall: 0.9720\n","Epoch 24/100\n","172/172 [==============================] - 2s 9ms/step - loss: 0.1106 - accuracy: 0.9573 - precision: 0.9660 - recall: 0.9880 - val_loss: 0.5868 - val_accuracy: 0.7915 - val_precision: 0.7123 - val_recall: 0.9780\n","Epoch 25/100\n","172/172 [==============================] - 2s 9ms/step - loss: 0.1046 - accuracy: 0.9601 - precision: 0.9694 - recall: 0.9874 - val_loss: 0.8555 - val_accuracy: 0.7310 - val_precision: 0.6526 - val_recall: 0.9880\n","Epoch 26/100\n","172/172 [==============================] - 2s 9ms/step - loss: 0.1039 - accuracy: 0.9594 - precision: 0.9681 - recall: 0.9880 - val_loss: 1.0419 - val_accuracy: 0.6600 - val_precision: 0.5962 - val_recall: 0.9920\n","Epoch 27/100\n","172/172 [==============================] - 2s 9ms/step - loss: 0.1146 - accuracy: 0.9532 - precision: 0.9666 - recall: 0.9826 - val_loss: 0.7357 - val_accuracy: 0.7680 - val_precision: 0.6872 - val_recall: 0.9840\n","Epoch 28/100\n","172/172 [==============================] - 2s 9ms/step - loss: 0.1057 - accuracy: 0.9606 - precision: 0.9696 - recall: 0.9878 - val_loss: 0.8040 - val_accuracy: 0.7220 - val_precision: 0.6451 - val_recall: 0.9870\n","Epoch 29/100\n","172/172 [==============================] - 2s 9ms/step - loss: 0.0956 - accuracy: 0.9615 - precision: 0.9715 - recall: 0.9868 - val_loss: 0.7037 - val_accuracy: 0.7805 - val_precision: 0.7002 - val_recall: 0.9810\n","Epoch 30/100\n","172/172 [==============================] - 2s 9ms/step - loss: 0.1071 - accuracy: 0.9583 - precision: 0.9697 - recall: 0.9850 - val_loss: 0.4225 - val_accuracy: 0.8560 - val_precision: 0.8117 - val_recall: 0.9270\n","Epoch 31/100\n","172/172 [==============================] - 2s 9ms/step - loss: 0.0932 - accuracy: 0.9634 - precision: 0.9739 - recall: 0.9862 - val_loss: 0.5605 - val_accuracy: 0.8095 - val_precision: 0.7350 - val_recall: 0.9680\n","Epoch 32/100\n","172/172 [==============================] - 2s 9ms/step - loss: 0.0891 - accuracy: 0.9655 - precision: 0.9749 - recall: 0.9876 - val_loss: 0.8590 - val_accuracy: 0.7460 - val_precision: 0.6660 - val_recall: 0.9870\n","Epoch 33/100\n","172/172 [==============================] - 2s 9ms/step - loss: 0.0990 - accuracy: 0.9608 - precision: 0.9707 - recall: 0.9868 - val_loss: 0.5733 - val_accuracy: 0.8180 - val_precision: 0.7420 - val_recall: 0.9750\n","Epoch 34/100\n","172/172 [==============================] - 2s 9ms/step - loss: 0.0845 - accuracy: 0.9676 - precision: 0.9763 - recall: 0.9884 - val_loss: 0.6364 - val_accuracy: 0.8125 - val_precision: 0.7351 - val_recall: 0.9770\n","Epoch 35/100\n","172/172 [==============================] - 2s 9ms/step - loss: 0.0791 - accuracy: 0.9679 - precision: 0.9765 - recall: 0.9886 - val_loss: 0.5904 - val_accuracy: 0.8245 - val_precision: 0.7533 - val_recall: 0.9650\n","Epoch 36/100\n","172/172 [==============================] - 2s 9ms/step - loss: 0.0885 - accuracy: 0.9654 - precision: 0.9747 - recall: 0.9876 - val_loss: 0.6469 - val_accuracy: 0.7945 - val_precision: 0.7167 - val_recall: 0.9740\n","Epoch 37/100\n","172/172 [==============================] - 2s 9ms/step - loss: 0.0864 - accuracy: 0.9670 - precision: 0.9757 - recall: 0.9884 - val_loss: 1.0270 - val_accuracy: 0.7135 - val_precision: 0.6373 - val_recall: 0.9910\n","Epoch 38/100\n","172/172 [==============================] - 2s 9ms/step - loss: 0.0726 - accuracy: 0.9732 - precision: 0.9795 - recall: 0.9914 - val_loss: 0.5022 - val_accuracy: 0.8460 - val_precision: 0.7827 - val_recall: 0.9580\n","Epoch 39/100\n","172/172 [==============================] - 2s 9ms/step - loss: 0.0774 - accuracy: 0.9681 - precision: 0.9769 - recall: 0.9884 - val_loss: 0.8171 - val_accuracy: 0.7680 - val_precision: 0.6882 - val_recall: 0.9800\n","Epoch 40/100\n","172/172 [==============================] - 2s 9ms/step - loss: 0.0693 - accuracy: 0.9747 - precision: 0.9816 - recall: 0.9908 - val_loss: 0.7332 - val_accuracy: 0.8060 - val_precision: 0.7277 - val_recall: 0.9780\n","Epoch 41/100\n","172/172 [==============================] - 2s 9ms/step - loss: 0.0713 - accuracy: 0.9712 - precision: 0.9798 - recall: 0.9888 - val_loss: 0.4693 - val_accuracy: 0.8550 - val_precision: 0.8008 - val_recall: 0.9450\n","Epoch 42/100\n","172/172 [==============================] - 2s 9ms/step - loss: 0.0636 - accuracy: 0.9759 - precision: 0.9831 - recall: 0.9906 - val_loss: 0.6263 - val_accuracy: 0.8220 - val_precision: 0.7508 - val_recall: 0.9640\n","Epoch 43/100\n","172/172 [==============================] - 2s 9ms/step - loss: 0.0580 - accuracy: 0.9792 - precision: 0.9861 - recall: 0.9912 - val_loss: 0.7347 - val_accuracy: 0.7980 - val_precision: 0.7214 - val_recall: 0.9710\n","Epoch 44/100\n","172/172 [==============================] - 2s 9ms/step - loss: 0.0653 - accuracy: 0.9754 - precision: 0.9835 - recall: 0.9896 - val_loss: 1.2860 - val_accuracy: 0.7005 - val_precision: 0.6273 - val_recall: 0.9880\n","Epoch 45/100\n","172/172 [==============================] - 2s 9ms/step - loss: 0.0650 - accuracy: 0.9756 - precision: 0.9835 - recall: 0.9898 - val_loss: 1.0162 - val_accuracy: 0.7550 - val_precision: 0.6737 - val_recall: 0.9890\n","Epoch 46/100\n","172/172 [==============================] - 2s 9ms/step - loss: 0.0605 - accuracy: 0.9754 - precision: 0.9843 - recall: 0.9888 - val_loss: 0.7324 - val_accuracy: 0.8030 - val_precision: 0.7265 - val_recall: 0.9720\n","Epoch 47/100\n","172/172 [==============================] - 2s 9ms/step - loss: 0.0486 - accuracy: 0.9823 - precision: 0.9873 - recall: 0.9934 - val_loss: 0.7920 - val_accuracy: 0.8050 - val_precision: 0.7266 - val_recall: 0.9780\n","Epoch 48/100\n","172/172 [==============================] - 2s 9ms/step - loss: 0.0580 - accuracy: 0.9770 - precision: 0.9835 - recall: 0.9914 - val_loss: 0.6946 - val_accuracy: 0.8325 - val_precision: 0.7612 - val_recall: 0.9690\n","Epoch 49/100\n","172/172 [==============================] - 2s 9ms/step - loss: 0.0674 - accuracy: 0.9767 - precision: 0.9841 - recall: 0.9904 - val_loss: 1.1724 - val_accuracy: 0.7385 - val_precision: 0.6587 - val_recall: 0.9900\n","Epoch 50/100\n","172/172 [==============================] - 2s 9ms/step - loss: 0.0542 - accuracy: 0.9810 - precision: 0.9859 - recall: 0.9934 - val_loss: 0.8718 - val_accuracy: 0.8075 - val_precision: 0.7283 - val_recall: 0.9810\n","Epoch 51/100\n","172/172 [==============================] - 2s 9ms/step - loss: 0.0547 - accuracy: 0.9805 - precision: 0.9873 - recall: 0.9914 - val_loss: 0.9013 - val_accuracy: 0.7535 - val_precision: 0.6740 - val_recall: 0.9820\n","Epoch 52/100\n","172/172 [==============================] - 2s 9ms/step - loss: 0.0466 - accuracy: 0.9840 - precision: 0.9890 - recall: 0.9934 - val_loss: 0.6460 - val_accuracy: 0.8450 - val_precision: 0.7769 - val_recall: 0.9680\n","Epoch 53/100\n","172/172 [==============================] - 2s 9ms/step - loss: 0.0420 - accuracy: 0.9863 - precision: 0.9902 - recall: 0.9948 - val_loss: 0.9193 - val_accuracy: 0.7850 - val_precision: 0.7042 - val_recall: 0.9830\n","Epoch 54/100\n","172/172 [==============================] - 2s 10ms/step - loss: 0.0586 - accuracy: 0.9789 - precision: 0.9859 - recall: 0.9910 - val_loss: 1.0545 - val_accuracy: 0.7540 - val_precision: 0.6733 - val_recall: 0.9870\n","Epoch 55/100\n","172/172 [==============================] - 2s 10ms/step - loss: 0.0468 - accuracy: 0.9825 - precision: 0.9888 - recall: 0.9920 - val_loss: 0.7339 - val_accuracy: 0.8285 - val_precision: 0.7548 - val_recall: 0.9730\n","Epoch 56/100\n","172/172 [==============================] - 2s 10ms/step - loss: 0.0453 - accuracy: 0.9814 - precision: 0.9886 - recall: 0.9910 - val_loss: 0.8259 - val_accuracy: 0.8050 - val_precision: 0.7276 - val_recall: 0.9750\n","Epoch 57/100\n","172/172 [==============================] - 2s 10ms/step - loss: 0.0415 - accuracy: 0.9861 - precision: 0.9904 - recall: 0.9944 - val_loss: 0.8622 - val_accuracy: 0.8035 - val_precision: 0.7260 - val_recall: 0.9750\n","Epoch 58/100\n","172/172 [==============================] - 2s 10ms/step - loss: 0.0540 - accuracy: 0.9787 - precision: 0.9861 - recall: 0.9906 - val_loss: 0.5744 - val_accuracy: 0.8525 - val_precision: 0.7930 - val_recall: 0.9540\n","Epoch 59/100\n","172/172 [==============================] - 2s 10ms/step - loss: 0.0441 - accuracy: 0.9847 - precision: 0.9889 - recall: 0.9944 - val_loss: 0.6307 - val_accuracy: 0.8525 - val_precision: 0.7950 - val_recall: 0.9500\n","Epoch 60/100\n","172/172 [==============================] - 2s 9ms/step - loss: 0.0496 - accuracy: 0.9801 - precision: 0.9874 - recall: 0.9908 - val_loss: 0.6733 - val_accuracy: 0.8325 - val_precision: 0.7649 - val_recall: 0.9600\n","Epoch 61/100\n","172/172 [==============================] - 2s 9ms/step - loss: 0.0389 - accuracy: 0.9849 - precision: 0.9910 - recall: 0.9924 - val_loss: 0.6843 - val_accuracy: 0.8415 - val_precision: 0.7743 - val_recall: 0.9640\n","Epoch 62/100\n","172/172 [==============================] - 2s 9ms/step - loss: 0.0410 - accuracy: 0.9858 - precision: 0.9904 - recall: 0.9940 - val_loss: 0.8978 - val_accuracy: 0.8120 - val_precision: 0.7371 - val_recall: 0.9700\n","Epoch 63/100\n","172/172 [==============================] - 2s 9ms/step - loss: 0.0520 - accuracy: 0.9807 - precision: 0.9880 - recall: 0.9908 - val_loss: 0.7304 - val_accuracy: 0.8395 - val_precision: 0.7736 - val_recall: 0.9600\n","Epoch 64/100\n","172/172 [==============================] - 2s 9ms/step - loss: 0.0288 - accuracy: 0.9914 - precision: 0.9944 - recall: 0.9962 - val_loss: 1.0850 - val_accuracy: 0.7910 - val_precision: 0.7112 - val_recall: 0.9800\n","Epoch 65/100\n","172/172 [==============================] - 2s 9ms/step - loss: 0.0300 - accuracy: 0.9911 - precision: 0.9946 - recall: 0.9956 - val_loss: 0.8556 - val_accuracy: 0.8165 - val_precision: 0.7422 - val_recall: 0.9700\n","Epoch 66/100\n","172/172 [==============================] - 2s 9ms/step - loss: 0.0397 - accuracy: 0.9858 - precision: 0.9900 - recall: 0.9944 - val_loss: 0.8885 - val_accuracy: 0.8160 - val_precision: 0.7409 - val_recall: 0.9720\n","Epoch 67/100\n","172/172 [==============================] - 2s 9ms/step - loss: 0.0308 - accuracy: 0.9882 - precision: 0.9922 - recall: 0.9948 - val_loss: 1.5566 - val_accuracy: 0.7390 - val_precision: 0.6589 - val_recall: 0.9910\n","Epoch 68/100\n","172/172 [==============================] - 2s 9ms/step - loss: 0.0415 - accuracy: 0.9823 - precision: 0.9881 - recall: 0.9926 - val_loss: 0.8990 - val_accuracy: 0.8195 - val_precision: 0.7471 - val_recall: 0.9660\n","Epoch 69/100\n","172/172 [==============================] - 2s 9ms/step - loss: 0.0248 - accuracy: 0.9923 - precision: 0.9950 - recall: 0.9966 - val_loss: 2.0167 - val_accuracy: 0.6630 - val_precision: 0.5984 - val_recall: 0.9910\n","Epoch 70/100\n","172/172 [==============================] - 2s 9ms/step - loss: 0.0281 - accuracy: 0.9894 - precision: 0.9930 - recall: 0.9954 - val_loss: 1.0345 - val_accuracy: 0.8070 - val_precision: 0.7281 - val_recall: 0.9800\n","Epoch 71/100\n","172/172 [==============================] - 2s 9ms/step - loss: 0.0375 - accuracy: 0.9878 - precision: 0.9926 - recall: 0.9940 - val_loss: 0.9842 - val_accuracy: 0.8110 - val_precision: 0.7345 - val_recall: 0.9740\n","Epoch 72/100\n","172/172 [==============================] - 1s 9ms/step - loss: 0.0348 - accuracy: 0.9869 - precision: 0.9924 - recall: 0.9932 - val_loss: 1.0027 - val_accuracy: 0.8210 - val_precision: 0.7450 - val_recall: 0.9760\n","Epoch 73/100\n","172/172 [==============================] - 2s 9ms/step - loss: 0.0421 - accuracy: 0.9821 - precision: 0.9888 - recall: 0.9916 - val_loss: 1.5901 - val_accuracy: 0.7285 - val_precision: 0.6506 - val_recall: 0.9870\n","Epoch 74/100\n","172/172 [==============================] - 2s 9ms/step - loss: 0.0300 - accuracy: 0.9874 - precision: 0.9920 - recall: 0.9942 - val_loss: 0.9337 - val_accuracy: 0.8135 - val_precision: 0.7391 - val_recall: 0.9690\n","Epoch 75/100\n","172/172 [==============================] - 2s 9ms/step - loss: 0.0260 - accuracy: 0.9913 - precision: 0.9946 - recall: 0.9958 - val_loss: 1.0902 - val_accuracy: 0.8070 - val_precision: 0.7277 - val_recall: 0.9810\n","Epoch 76/100\n","172/172 [==============================] - 2s 9ms/step - loss: 0.0230 - accuracy: 0.9934 - precision: 0.9954 - recall: 0.9974 - val_loss: 1.1659 - val_accuracy: 0.8020 - val_precision: 0.7224 - val_recall: 0.9810\n","Epoch 77/100\n","172/172 [==============================] - 2s 9ms/step - loss: 0.0278 - accuracy: 0.9898 - precision: 0.9942 - recall: 0.9946 - val_loss: 1.0321 - val_accuracy: 0.8115 - val_precision: 0.7351 - val_recall: 0.9740\n","Epoch 78/100\n","172/172 [==============================] - 2s 9ms/step - loss: 0.0178 - accuracy: 0.9945 - precision: 0.9970 - recall: 0.9970 - val_loss: 1.3532 - val_accuracy: 0.7755 - val_precision: 0.6947 - val_recall: 0.9830\n","Epoch 79/100\n","172/172 [==============================] - 2s 9ms/step - loss: 0.0233 - accuracy: 0.9911 - precision: 0.9938 - recall: 0.9964 - val_loss: 1.3585 - val_accuracy: 0.7800 - val_precision: 0.6991 - val_recall: 0.9830\n","Epoch 80/100\n","172/172 [==============================] - 2s 9ms/step - loss: 0.0140 - accuracy: 0.9969 - precision: 0.9988 - recall: 0.9978 - val_loss: 1.1456 - val_accuracy: 0.8155 - val_precision: 0.7378 - val_recall: 0.9790\n","Epoch 81/100\n","172/172 [==============================] - 2s 9ms/step - loss: 0.0172 - accuracy: 0.9953 - precision: 0.9974 - recall: 0.9974 - val_loss: 0.9656 - val_accuracy: 0.8285 - val_precision: 0.7545 - val_recall: 0.9740\n","Epoch 82/100\n","172/172 [==============================] - 2s 10ms/step - loss: 0.0413 - accuracy: 0.9851 - precision: 0.9904 - recall: 0.9932 - val_loss: 0.8717 - val_accuracy: 0.8530 - val_precision: 0.7942 - val_recall: 0.9530\n","Epoch 83/100\n","172/172 [==============================] - 2s 9ms/step - loss: 0.0170 - accuracy: 0.9951 - precision: 0.9962 - recall: 0.9984 - val_loss: 1.2025 - val_accuracy: 0.8040 - val_precision: 0.7252 - val_recall: 0.9790\n","Epoch 84/100\n","172/172 [==============================] - 1s 9ms/step - loss: 0.0379 - accuracy: 0.9861 - precision: 0.9926 - recall: 0.9922 - val_loss: 2.0166 - val_accuracy: 0.6865 - val_precision: 0.6161 - val_recall: 0.9900\n","Epoch 85/100\n","172/172 [==============================] - 2s 9ms/step - loss: 0.0296 - accuracy: 0.9869 - precision: 0.9920 - recall: 0.9936 - val_loss: 1.4985 - val_accuracy: 0.7680 - val_precision: 0.6866 - val_recall: 0.9860\n","Epoch 86/100\n","172/172 [==============================] - 2s 9ms/step - loss: 0.0270 - accuracy: 0.9887 - precision: 0.9924 - recall: 0.9952 - val_loss: 1.1777 - val_accuracy: 0.7975 - val_precision: 0.7189 - val_recall: 0.9770\n","Epoch 87/100\n","172/172 [==============================] - 2s 9ms/step - loss: 0.0144 - accuracy: 0.9965 - precision: 0.9982 - recall: 0.9980 - val_loss: 1.1336 - val_accuracy: 0.8190 - val_precision: 0.7431 - val_recall: 0.9750\n","Epoch 88/100\n","172/172 [==============================] - 2s 9ms/step - loss: 0.0260 - accuracy: 0.9909 - precision: 0.9952 - recall: 0.9948 - val_loss: 1.0986 - val_accuracy: 0.8200 - val_precision: 0.7446 - val_recall: 0.9740\n","Epoch 89/100\n","172/172 [==============================] - 2s 9ms/step - loss: 0.0107 - accuracy: 0.9971 - precision: 0.9986 - recall: 0.9982 - val_loss: 1.2551 - val_accuracy: 0.8110 - val_precision: 0.7338 - val_recall: 0.9760\n","Epoch 90/100\n","172/172 [==============================] - 2s 9ms/step - loss: 0.0134 - accuracy: 0.9953 - precision: 0.9972 - recall: 0.9976 - val_loss: 1.3373 - val_accuracy: 0.7890 - val_precision: 0.7085 - val_recall: 0.9820\n","Epoch 91/100\n","172/172 [==============================] - 2s 9ms/step - loss: 0.0191 - accuracy: 0.9929 - precision: 0.9956 - recall: 0.9966 - val_loss: 1.1984 - val_accuracy: 0.8115 - val_precision: 0.7376 - val_recall: 0.9670\n","Epoch 92/100\n","172/172 [==============================] - 2s 9ms/step - loss: 0.0311 - accuracy: 0.9891 - precision: 0.9928 - recall: 0.9952 - val_loss: 1.5951 - val_accuracy: 0.7680 - val_precision: 0.6861 - val_recall: 0.9880\n","Epoch 93/100\n","172/172 [==============================] - 2s 9ms/step - loss: 0.0262 - accuracy: 0.9905 - precision: 0.9938 - recall: 0.9958 - val_loss: 0.9105 - val_accuracy: 0.8430 - val_precision: 0.7789 - val_recall: 0.9580\n","Epoch 94/100\n","172/172 [==============================] - 2s 9ms/step - loss: 0.0149 - accuracy: 0.9945 - precision: 0.9964 - recall: 0.9976 - val_loss: 1.3569 - val_accuracy: 0.8020 - val_precision: 0.7217 - val_recall: 0.9830\n","Epoch 95/100\n","172/172 [==============================] - 1s 9ms/step - loss: 0.0162 - accuracy: 0.9943 - precision: 0.9960 - recall: 0.9978 - val_loss: 1.3002 - val_accuracy: 0.8125 - val_precision: 0.7355 - val_recall: 0.9760\n","Epoch 96/100\n","172/172 [==============================] - 2s 9ms/step - loss: 0.0459 - accuracy: 0.9827 - precision: 0.9894 - recall: 0.9916 - val_loss: 1.5539 - val_accuracy: 0.7585 - val_precision: 0.6789 - val_recall: 0.9810\n","Epoch 97/100\n","172/172 [==============================] - 2s 9ms/step - loss: 0.0248 - accuracy: 0.9923 - precision: 0.9956 - recall: 0.9960 - val_loss: 1.2867 - val_accuracy: 0.8030 - val_precision: 0.7251 - val_recall: 0.9760\n","Epoch 98/100\n","172/172 [==============================] - 2s 9ms/step - loss: 0.0228 - accuracy: 0.9929 - precision: 0.9952 - recall: 0.9970 - val_loss: 1.3583 - val_accuracy: 0.7910 - val_precision: 0.7112 - val_recall: 0.9800\n","Epoch 99/100\n","172/172 [==============================] - 2s 9ms/step - loss: 0.0097 - accuracy: 0.9973 - precision: 0.9984 - recall: 0.9986 - val_loss: 1.1955 - val_accuracy: 0.8295 - val_precision: 0.7588 - val_recall: 0.9660\n","Epoch 100/100\n","172/172 [==============================] - 1s 9ms/step - loss: 0.0288 - accuracy: 0.9885 - precision: 0.9930 - recall: 0.9944 - val_loss: 1.0502 - val_accuracy: 0.8210 - val_precision: 0.7488 - val_recall: 0.9660\n"],"name":"stdout"},{"output_type":"execute_result","data":{"text/plain":["<tensorflow.python.keras.callbacks.History at 0x7f529fdbde10>"]},"metadata":{"tags":[]},"execution_count":5}]},{"cell_type":"markdown","metadata":{"id":"DXh2vXbjYWpo","colab_type":"text"},"source":["#불균형한 데이터셋을 Borderline SMOTE사용하여 맞춰준다."]},{"cell_type":"code","metadata":{"id":"vUOyUEcsYhbY","colab_type":"code","colab":{"base_uri":"https://localhost:8080/","height":119},"executionInfo":{"status":"ok","timestamp":1597500030074,"user_tz":-540,"elapsed":5764,"user":{"displayName":"김준기","photoUrl":"","userId":"08456149661061922976"}},"outputId":"b0eb37ed-68f7-4e25-b0b7-76005accc546"},"source":[" pip install imblearn"],"execution_count":6,"outputs":[{"output_type":"stream","text":["Requirement already satisfied: imblearn in /usr/local/lib/python3.6/dist-packages (0.0)\n","Requirement already satisfied: imbalanced-learn in /usr/local/lib/python3.6/dist-packages (from imblearn) (0.4.3)\n","Requirement already satisfied: numpy>=1.8.2 in /usr/local/lib/python3.6/dist-packages (from imbalanced-learn->imblearn) (1.18.5)\n","Requirement already satisfied: scipy>=0.13.3 in /usr/local/lib/python3.6/dist-packages (from imbalanced-learn->imblearn) (1.4.1)\n","Requirement already satisfied: scikit-learn>=0.20 in /usr/local/lib/python3.6/dist-packages (from imbalanced-learn->imblearn) (0.22.2.post1)\n","Requirement already satisfied: joblib>=0.11 in /usr/local/lib/python3.6/dist-packages (from scikit-learn>=0.20->imbalanced-learn->imblearn) (0.16.0)\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"StP4yKbza-O9","colab_type":"code","colab":{},"executionInfo":{"status":"ok","timestamp":1597500056284,"user_tz":-540,"elapsed":763,"user":{"displayName":"김준기","photoUrl":"","userId":"08456149661061922976"}}},"source":["from imblearn.over_sampling import BorderlineSMOTE"],"execution_count":7,"outputs":[]},{"cell_type":"code","metadata":{"id":"v-J9EFhPbF-v","colab_type":"code","colab":{"base_uri":"https://localhost:8080/","height":173},"executionInfo":{"status":"ok","timestamp":1597500199414,"user_tz":-540,"elapsed":20006,"user":{"displayName":"김준기","photoUrl":"","userId":"08456149661061922976"}},"outputId":"26ba7ac5-748e-450d-9337-287869714888"},"source":["smote = BorderlineSMOTE()\n","\n","x_train = x_train.reshape((x_train.shape[0], x_train.shape[1] * x_train.shape[2] * x_train.shape[3])).astype(np.float32)\n","x_test = x_test.reshape((x_test.shape[0], x_test.shape[1] * x_test.shape[2] * x_test.shape[3])).astype(np.float32)\n","\n","x_train, y_train = smote.fit_resample(x_train,y_train)\n","\n","\n","train_ds = tf.data.Dataset.from_tensor_slices((x_train,y_train)).shuffle(10000).batch(32).prefetch(2048)\n","test_ds = tf.data.Dataset.from_tensor_slices((x_test,y_test)).batch(32).prefetch(2048)"],"execution_count":8,"outputs":[{"output_type":"stream","text":["/usr/local/lib/python3.6/dist-packages/sklearn/utils/validation.py:760: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n","  y = column_or_1d(y, warn=True)\n","/usr/local/lib/python3.6/dist-packages/sklearn/utils/deprecation.py:87: FutureWarning: Function safe_indexing is deprecated; safe_indexing is deprecated in version 0.22 and will be removed in version 0.24.\n","  warnings.warn(msg, category=FutureWarning)\n","/usr/local/lib/python3.6/dist-packages/sklearn/utils/deprecation.py:87: FutureWarning: Function safe_indexing is deprecated; safe_indexing is deprecated in version 0.22 and will be removed in version 0.24.\n","  warnings.warn(msg, category=FutureWarning)\n","/usr/local/lib/python3.6/dist-packages/sklearn/utils/deprecation.py:87: FutureWarning: Function safe_indexing is deprecated; safe_indexing is deprecated in version 0.22 and will be removed in version 0.24.\n","  warnings.warn(msg, category=FutureWarning)\n"],"name":"stderr"}]},{"cell_type":"code","metadata":{"id":"f7ln7ArJbkOS","colab_type":"code","colab":{"base_uri":"https://localhost:8080/","height":1000},"executionInfo":{"status":"ok","timestamp":1597500464724,"user_tz":-540,"elapsed":262973,"user":{"displayName":"김준기","photoUrl":"","userId":"08456149661061922976"}},"outputId":"facd7c08-4391-4ec1-b959-20d43c30600b"},"source":["model = MyModel()\n","model.compile(optimizer='adam',\n","              loss='binary_crossentropy',\n","              metrics=['accuracy',\n","                       tf.keras.metrics.Precision(name='precision'),#shallow nn 이라 좀 보조해줄거\n","                       tf.keras.metrics.Recall(name='recall')])\n","model.fit(train_ds, validation_data = test_ds, epochs = EPOCHS)\n","#loss가 존나 낮아지면서 학습이 잘 되는걸 확인할 수 있다."],"execution_count":9,"outputs":[{"output_type":"stream","text":["Epoch 1/100\n","313/313 [==============================] - 3s 9ms/step - loss: 0.5733 - accuracy: 0.7518 - precision: 0.7711 - recall: 0.7162 - val_loss: 0.4514 - val_accuracy: 0.7795 - val_precision: 0.8542 - val_recall: 0.6740\n","Epoch 2/100\n","313/313 [==============================] - 2s 8ms/step - loss: 0.3964 - accuracy: 0.8249 - precision: 0.8520 - recall: 0.7864 - val_loss: 0.4384 - val_accuracy: 0.7920 - val_precision: 0.8724 - val_recall: 0.6840\n","Epoch 3/100\n","313/313 [==============================] - 2s 8ms/step - loss: 0.3138 - accuracy: 0.8707 - precision: 0.9053 - recall: 0.8280 - val_loss: 0.4636 - val_accuracy: 0.8125 - val_precision: 0.7692 - val_recall: 0.8930\n","Epoch 4/100\n","313/313 [==============================] - 2s 8ms/step - loss: 0.2618 - accuracy: 0.8992 - precision: 0.9320 - recall: 0.8612 - val_loss: 0.5038 - val_accuracy: 0.8125 - val_precision: 0.7585 - val_recall: 0.9170\n","Epoch 5/100\n","313/313 [==============================] - 2s 8ms/step - loss: 0.2335 - accuracy: 0.9112 - precision: 0.9404 - recall: 0.8780 - val_loss: 0.4819 - val_accuracy: 0.8350 - val_precision: 0.7878 - val_recall: 0.9170\n","Epoch 6/100\n","313/313 [==============================] - 2s 8ms/step - loss: 0.1882 - accuracy: 0.9332 - precision: 0.9591 - recall: 0.9050 - val_loss: 0.5108 - val_accuracy: 0.8220 - val_precision: 0.7688 - val_recall: 0.9210\n","Epoch 7/100\n","313/313 [==============================] - 2s 8ms/step - loss: 0.1792 - accuracy: 0.9369 - precision: 0.9590 - recall: 0.9128 - val_loss: 0.4832 - val_accuracy: 0.8425 - val_precision: 0.7971 - val_recall: 0.9190\n","Epoch 8/100\n","313/313 [==============================] - 2s 8ms/step - loss: 0.1487 - accuracy: 0.9504 - precision: 0.9725 - recall: 0.9270 - val_loss: 0.5195 - val_accuracy: 0.8370 - val_precision: 0.7871 - val_recall: 0.9240\n","Epoch 9/100\n","313/313 [==============================] - 2s 8ms/step - loss: 0.1294 - accuracy: 0.9580 - precision: 0.9751 - recall: 0.9400 - val_loss: 0.7368 - val_accuracy: 0.8000 - val_precision: 0.7252 - val_recall: 0.9660\n","Epoch 10/100\n","313/313 [==============================] - 2s 8ms/step - loss: 0.1215 - accuracy: 0.9604 - precision: 0.9762 - recall: 0.9438 - val_loss: 0.7325 - val_accuracy: 0.8065 - val_precision: 0.7341 - val_recall: 0.9610\n","Epoch 11/100\n","313/313 [==============================] - 2s 8ms/step - loss: 0.1028 - accuracy: 0.9674 - precision: 0.9799 - recall: 0.9544 - val_loss: 0.7010 - val_accuracy: 0.8170 - val_precision: 0.7461 - val_recall: 0.9610\n","Epoch 12/100\n","313/313 [==============================] - 2s 8ms/step - loss: 0.1039 - accuracy: 0.9679 - precision: 0.9770 - recall: 0.9584 - val_loss: 0.6645 - val_accuracy: 0.8335 - val_precision: 0.7692 - val_recall: 0.9530\n","Epoch 13/100\n","313/313 [==============================] - 2s 8ms/step - loss: 0.1020 - accuracy: 0.9679 - precision: 0.9779 - recall: 0.9574 - val_loss: 0.8629 - val_accuracy: 0.8010 - val_precision: 0.7253 - val_recall: 0.9690\n","Epoch 14/100\n","313/313 [==============================] - 2s 8ms/step - loss: 0.1003 - accuracy: 0.9678 - precision: 0.9783 - recall: 0.9568 - val_loss: 0.6756 - val_accuracy: 0.8385 - val_precision: 0.7818 - val_recall: 0.9390\n","Epoch 15/100\n","313/313 [==============================] - 2s 8ms/step - loss: 0.0801 - accuracy: 0.9758 - precision: 0.9845 - recall: 0.9668 - val_loss: 0.9128 - val_accuracy: 0.7945 - val_precision: 0.7170 - val_recall: 0.9730\n","Epoch 16/100\n","313/313 [==============================] - 2s 8ms/step - loss: 0.0905 - accuracy: 0.9719 - precision: 0.9808 - recall: 0.9626 - val_loss: 0.6682 - val_accuracy: 0.8475 - val_precision: 0.7973 - val_recall: 0.9320\n","Epoch 17/100\n","313/313 [==============================] - 2s 8ms/step - loss: 0.0713 - accuracy: 0.9782 - precision: 0.9850 - recall: 0.9712 - val_loss: 0.7089 - val_accuracy: 0.8430 - val_precision: 0.7825 - val_recall: 0.9500\n","Epoch 18/100\n","313/313 [==============================] - 2s 8ms/step - loss: 0.0900 - accuracy: 0.9708 - precision: 0.9773 - recall: 0.9640 - val_loss: 0.6647 - val_accuracy: 0.8225 - val_precision: 0.7872 - val_recall: 0.8840\n","Epoch 19/100\n","313/313 [==============================] - 2s 8ms/step - loss: 0.0899 - accuracy: 0.9708 - precision: 0.9796 - recall: 0.9616 - val_loss: 0.6843 - val_accuracy: 0.8385 - val_precision: 0.7795 - val_recall: 0.9440\n","Epoch 20/100\n","313/313 [==============================] - 2s 8ms/step - loss: 0.0646 - accuracy: 0.9802 - precision: 0.9868 - recall: 0.9734 - val_loss: 1.0455 - val_accuracy: 0.7760 - val_precision: 0.6994 - val_recall: 0.9680\n","Epoch 21/100\n","313/313 [==============================] - 2s 8ms/step - loss: 0.0648 - accuracy: 0.9804 - precision: 0.9862 - recall: 0.9744 - val_loss: 1.6952 - val_accuracy: 0.6835 - val_precision: 0.6138 - val_recall: 0.9900\n","Epoch 22/100\n","313/313 [==============================] - 2s 8ms/step - loss: 0.0696 - accuracy: 0.9799 - precision: 0.9868 - recall: 0.9728 - val_loss: 0.8275 - val_accuracy: 0.8120 - val_precision: 0.7434 - val_recall: 0.9530\n","Epoch 23/100\n","313/313 [==============================] - 2s 8ms/step - loss: 0.0616 - accuracy: 0.9813 - precision: 0.9851 - recall: 0.9774 - val_loss: 0.6039 - val_accuracy: 0.8575 - val_precision: 0.8326 - val_recall: 0.8950\n","Epoch 24/100\n","313/313 [==============================] - 2s 8ms/step - loss: 0.0515 - accuracy: 0.9866 - precision: 0.9891 - recall: 0.9840 - val_loss: 0.6873 - val_accuracy: 0.8455 - val_precision: 0.7916 - val_recall: 0.9380\n","Epoch 25/100\n","313/313 [==============================] - 2s 8ms/step - loss: 0.0560 - accuracy: 0.9816 - precision: 0.9863 - recall: 0.9768 - val_loss: 0.7319 - val_accuracy: 0.8465 - val_precision: 0.7900 - val_recall: 0.9440\n","Epoch 26/100\n","313/313 [==============================] - 2s 8ms/step - loss: 0.0496 - accuracy: 0.9853 - precision: 0.9887 - recall: 0.9818 - val_loss: 1.3214 - val_accuracy: 0.7565 - val_precision: 0.6778 - val_recall: 0.9780\n","Epoch 27/100\n","313/313 [==============================] - 2s 8ms/step - loss: 0.0693 - accuracy: 0.9786 - precision: 0.9825 - recall: 0.9746 - val_loss: 0.9709 - val_accuracy: 0.8175 - val_precision: 0.7452 - val_recall: 0.9650\n","Epoch 28/100\n","313/313 [==============================] - 2s 8ms/step - loss: 0.0567 - accuracy: 0.9820 - precision: 0.9865 - recall: 0.9774 - val_loss: 0.8225 - val_accuracy: 0.8435 - val_precision: 0.7832 - val_recall: 0.9500\n","Epoch 29/100\n","313/313 [==============================] - 2s 8ms/step - loss: 0.0522 - accuracy: 0.9828 - precision: 0.9855 - recall: 0.9800 - val_loss: 1.4051 - val_accuracy: 0.7690 - val_precision: 0.6892 - val_recall: 0.9800\n","Epoch 30/100\n","313/313 [==============================] - 2s 8ms/step - loss: 0.0557 - accuracy: 0.9831 - precision: 0.9869 - recall: 0.9792 - val_loss: 0.9516 - val_accuracy: 0.8280 - val_precision: 0.7591 - val_recall: 0.9610\n","Epoch 31/100\n","313/313 [==============================] - 2s 8ms/step - loss: 0.0411 - accuracy: 0.9888 - precision: 0.9912 - recall: 0.9864 - val_loss: 1.2999 - val_accuracy: 0.7900 - val_precision: 0.7108 - val_recall: 0.9780\n","Epoch 32/100\n","313/313 [==============================] - 2s 8ms/step - loss: 0.0409 - accuracy: 0.9879 - precision: 0.9907 - recall: 0.9850 - val_loss: 1.3305 - val_accuracy: 0.7625 - val_precision: 0.6850 - val_recall: 0.9720\n","Epoch 33/100\n","313/313 [==============================] - 2s 8ms/step - loss: 0.0464 - accuracy: 0.9848 - precision: 0.9877 - recall: 0.9818 - val_loss: 0.9964 - val_accuracy: 0.8220 - val_precision: 0.7520 - val_recall: 0.9610\n","Epoch 34/100\n","313/313 [==============================] - 2s 8ms/step - loss: 0.0425 - accuracy: 0.9866 - precision: 0.9897 - recall: 0.9834 - val_loss: 1.1899 - val_accuracy: 0.7980 - val_precision: 0.7207 - val_recall: 0.9730\n","Epoch 35/100\n","313/313 [==============================] - 2s 8ms/step - loss: 0.0431 - accuracy: 0.9878 - precision: 0.9905 - recall: 0.9850 - val_loss: 0.7104 - val_accuracy: 0.8595 - val_precision: 0.8253 - val_recall: 0.9120\n","Epoch 36/100\n","313/313 [==============================] - 3s 8ms/step - loss: 0.0456 - accuracy: 0.9857 - precision: 0.9895 - recall: 0.9818 - val_loss: 1.5516 - val_accuracy: 0.7390 - val_precision: 0.6615 - val_recall: 0.9790\n","Epoch 37/100\n","313/313 [==============================] - 2s 8ms/step - loss: 0.0366 - accuracy: 0.9896 - precision: 0.9926 - recall: 0.9866 - val_loss: 0.8916 - val_accuracy: 0.8415 - val_precision: 0.7834 - val_recall: 0.9440\n","Epoch 38/100\n","313/313 [==============================] - 2s 8ms/step - loss: 0.0369 - accuracy: 0.9887 - precision: 0.9917 - recall: 0.9856 - val_loss: 1.1078 - val_accuracy: 0.8155 - val_precision: 0.7433 - val_recall: 0.9640\n","Epoch 39/100\n","313/313 [==============================] - 2s 8ms/step - loss: 0.0368 - accuracy: 0.9891 - precision: 0.9918 - recall: 0.9864 - val_loss: 1.0614 - val_accuracy: 0.8205 - val_precision: 0.7538 - val_recall: 0.9520\n","Epoch 40/100\n","313/313 [==============================] - 2s 8ms/step - loss: 0.0464 - accuracy: 0.9847 - precision: 0.9869 - recall: 0.9824 - val_loss: 1.0337 - val_accuracy: 0.8225 - val_precision: 0.7529 - val_recall: 0.9600\n","Epoch 41/100\n","313/313 [==============================] - 2s 8ms/step - loss: 0.0305 - accuracy: 0.9908 - precision: 0.9936 - recall: 0.9880 - val_loss: 1.5203 - val_accuracy: 0.7635 - val_precision: 0.6852 - val_recall: 0.9750\n","Epoch 42/100\n","313/313 [==============================] - 2s 8ms/step - loss: 0.0297 - accuracy: 0.9908 - precision: 0.9934 - recall: 0.9882 - val_loss: 1.1341 - val_accuracy: 0.8230 - val_precision: 0.7520 - val_recall: 0.9640\n","Epoch 43/100\n","313/313 [==============================] - 2s 8ms/step - loss: 0.0398 - accuracy: 0.9879 - precision: 0.9892 - recall: 0.9866 - val_loss: 1.0350 - val_accuracy: 0.8200 - val_precision: 0.7504 - val_recall: 0.9590\n","Epoch 44/100\n","313/313 [==============================] - 2s 8ms/step - loss: 0.0299 - accuracy: 0.9907 - precision: 0.9926 - recall: 0.9888 - val_loss: 1.0971 - val_accuracy: 0.8175 - val_precision: 0.7522 - val_recall: 0.9470\n","Epoch 45/100\n","313/313 [==============================] - 2s 8ms/step - loss: 0.0358 - accuracy: 0.9881 - precision: 0.9909 - recall: 0.9852 - val_loss: 1.3147 - val_accuracy: 0.7920 - val_precision: 0.7160 - val_recall: 0.9680\n","Epoch 46/100\n","313/313 [==============================] - 2s 8ms/step - loss: 0.0204 - accuracy: 0.9939 - precision: 0.9958 - recall: 0.9920 - val_loss: 1.4126 - val_accuracy: 0.7900 - val_precision: 0.7111 - val_recall: 0.9770\n","Epoch 47/100\n","313/313 [==============================] - 2s 8ms/step - loss: 0.0362 - accuracy: 0.9881 - precision: 0.9909 - recall: 0.9852 - val_loss: 1.2805 - val_accuracy: 0.7985 - val_precision: 0.7243 - val_recall: 0.9640\n","Epoch 48/100\n","313/313 [==============================] - 2s 8ms/step - loss: 0.0333 - accuracy: 0.9892 - precision: 0.9924 - recall: 0.9860 - val_loss: 1.0376 - val_accuracy: 0.8280 - val_precision: 0.7611 - val_recall: 0.9560\n","Epoch 49/100\n","313/313 [==============================] - 3s 8ms/step - loss: 0.0350 - accuracy: 0.9886 - precision: 0.9904 - recall: 0.9868 - val_loss: 1.3039 - val_accuracy: 0.8165 - val_precision: 0.7429 - val_recall: 0.9680\n","Epoch 50/100\n","313/313 [==============================] - 2s 8ms/step - loss: 0.0190 - accuracy: 0.9934 - precision: 0.9948 - recall: 0.9920 - val_loss: 1.1753 - val_accuracy: 0.8155 - val_precision: 0.7467 - val_recall: 0.9550\n","Epoch 51/100\n","313/313 [==============================] - 2s 8ms/step - loss: 0.0250 - accuracy: 0.9922 - precision: 0.9940 - recall: 0.9904 - val_loss: 1.0682 - val_accuracy: 0.8340 - val_precision: 0.7720 - val_recall: 0.9480\n","Epoch 52/100\n","313/313 [==============================] - 2s 8ms/step - loss: 0.0346 - accuracy: 0.9882 - precision: 0.9896 - recall: 0.9868 - val_loss: 1.1492 - val_accuracy: 0.8300 - val_precision: 0.7611 - val_recall: 0.9620\n","Epoch 53/100\n","313/313 [==============================] - 2s 8ms/step - loss: 0.0431 - accuracy: 0.9848 - precision: 0.9881 - recall: 0.9814 - val_loss: 2.0616 - val_accuracy: 0.7375 - val_precision: 0.6580 - val_recall: 0.9890\n","Epoch 54/100\n","313/313 [==============================] - 2s 8ms/step - loss: 0.0447 - accuracy: 0.9844 - precision: 0.9883 - recall: 0.9804 - val_loss: 1.2068 - val_accuracy: 0.8180 - val_precision: 0.7439 - val_recall: 0.9700\n","Epoch 55/100\n","313/313 [==============================] - 2s 8ms/step - loss: 0.0210 - accuracy: 0.9940 - precision: 0.9956 - recall: 0.9924 - val_loss: 1.1474 - val_accuracy: 0.8220 - val_precision: 0.7516 - val_recall: 0.9620\n","Epoch 56/100\n","313/313 [==============================] - 2s 8ms/step - loss: 0.0210 - accuracy: 0.9936 - precision: 0.9948 - recall: 0.9924 - val_loss: 1.5063 - val_accuracy: 0.7905 - val_precision: 0.7150 - val_recall: 0.9660\n","Epoch 57/100\n","313/313 [==============================] - 2s 8ms/step - loss: 0.0177 - accuracy: 0.9949 - precision: 0.9960 - recall: 0.9938 - val_loss: 1.0603 - val_accuracy: 0.8525 - val_precision: 0.7925 - val_recall: 0.9550\n","Epoch 58/100\n","313/313 [==============================] - 2s 8ms/step - loss: 0.0216 - accuracy: 0.9928 - precision: 0.9940 - recall: 0.9916 - val_loss: 1.7400 - val_accuracy: 0.7850 - val_precision: 0.7068 - val_recall: 0.9740\n","Epoch 59/100\n","313/313 [==============================] - 2s 8ms/step - loss: 0.0305 - accuracy: 0.9909 - precision: 0.9928 - recall: 0.9890 - val_loss: 1.7795 - val_accuracy: 0.7820 - val_precision: 0.7026 - val_recall: 0.9780\n","Epoch 60/100\n","313/313 [==============================] - 2s 8ms/step - loss: 0.0155 - accuracy: 0.9959 - precision: 0.9972 - recall: 0.9946 - val_loss: 1.5913 - val_accuracy: 0.8015 - val_precision: 0.7238 - val_recall: 0.9750\n","Epoch 61/100\n","313/313 [==============================] - 2s 8ms/step - loss: 0.0155 - accuracy: 0.9961 - precision: 0.9978 - recall: 0.9944 - val_loss: 1.8269 - val_accuracy: 0.7820 - val_precision: 0.7023 - val_recall: 0.9790\n","Epoch 62/100\n","313/313 [==============================] - 2s 8ms/step - loss: 0.0136 - accuracy: 0.9958 - precision: 0.9972 - recall: 0.9944 - val_loss: 1.3797 - val_accuracy: 0.8160 - val_precision: 0.7412 - val_recall: 0.9710\n","Epoch 63/100\n","313/313 [==============================] - 2s 8ms/step - loss: 0.0201 - accuracy: 0.9945 - precision: 0.9950 - recall: 0.9940 - val_loss: 1.8175 - val_accuracy: 0.7930 - val_precision: 0.7148 - val_recall: 0.9750\n","Epoch 64/100\n","313/313 [==============================] - 2s 8ms/step - loss: 0.0222 - accuracy: 0.9915 - precision: 0.9930 - recall: 0.9900 - val_loss: 1.8437 - val_accuracy: 0.7780 - val_precision: 0.6991 - val_recall: 0.9760\n","Epoch 65/100\n","313/313 [==============================] - 2s 8ms/step - loss: 0.0297 - accuracy: 0.9904 - precision: 0.9922 - recall: 0.9886 - val_loss: 2.3543 - val_accuracy: 0.7250 - val_precision: 0.6476 - val_recall: 0.9870\n","Epoch 66/100\n","313/313 [==============================] - 2s 8ms/step - loss: 0.0196 - accuracy: 0.9935 - precision: 0.9944 - recall: 0.9926 - val_loss: 1.3973 - val_accuracy: 0.8225 - val_precision: 0.7514 - val_recall: 0.9640\n","Epoch 67/100\n","313/313 [==============================] - 2s 8ms/step - loss: 0.0185 - accuracy: 0.9943 - precision: 0.9954 - recall: 0.9932 - val_loss: 1.1245 - val_accuracy: 0.8335 - val_precision: 0.7768 - val_recall: 0.9360\n","Epoch 68/100\n","313/313 [==============================] - 2s 8ms/step - loss: 0.0231 - accuracy: 0.9929 - precision: 0.9948 - recall: 0.9910 - val_loss: 2.0923 - val_accuracy: 0.7675 - val_precision: 0.6869 - val_recall: 0.9830\n","Epoch 69/100\n","313/313 [==============================] - 3s 8ms/step - loss: 0.0176 - accuracy: 0.9943 - precision: 0.9948 - recall: 0.9938 - val_loss: 1.7866 - val_accuracy: 0.7795 - val_precision: 0.7009 - val_recall: 0.9750\n","Epoch 70/100\n","313/313 [==============================] - 2s 8ms/step - loss: 0.0136 - accuracy: 0.9956 - precision: 0.9970 - recall: 0.9942 - val_loss: 1.5063 - val_accuracy: 0.8085 - val_precision: 0.7325 - val_recall: 0.9720\n","Epoch 71/100\n","313/313 [==============================] - 2s 8ms/step - loss: 0.0206 - accuracy: 0.9940 - precision: 0.9954 - recall: 0.9926 - val_loss: 1.0599 - val_accuracy: 0.8495 - val_precision: 0.7944 - val_recall: 0.9430\n","Epoch 72/100\n","313/313 [==============================] - 2s 8ms/step - loss: 0.0146 - accuracy: 0.9958 - precision: 0.9968 - recall: 0.9948 - val_loss: 1.0650 - val_accuracy: 0.8570 - val_precision: 0.8094 - val_recall: 0.9340\n","Epoch 73/100\n","313/313 [==============================] - 2s 8ms/step - loss: 0.0285 - accuracy: 0.9911 - precision: 0.9938 - recall: 0.9884 - val_loss: 1.3007 - val_accuracy: 0.8315 - val_precision: 0.7641 - val_recall: 0.9590\n","Epoch 74/100\n","313/313 [==============================] - 2s 8ms/step - loss: 0.0234 - accuracy: 0.9930 - precision: 0.9938 - recall: 0.9922 - val_loss: 1.8664 - val_accuracy: 0.7765 - val_precision: 0.6976 - val_recall: 0.9760\n","Epoch 75/100\n","313/313 [==============================] - 2s 8ms/step - loss: 0.0183 - accuracy: 0.9935 - precision: 0.9952 - recall: 0.9918 - val_loss: 1.4243 - val_accuracy: 0.8300 - val_precision: 0.7594 - val_recall: 0.9660\n","Epoch 76/100\n","313/313 [==============================] - 2s 8ms/step - loss: 0.0132 - accuracy: 0.9954 - precision: 0.9966 - recall: 0.9942 - val_loss: 1.4558 - val_accuracy: 0.8080 - val_precision: 0.7373 - val_recall: 0.9570\n","Epoch 77/100\n","313/313 [==============================] - 2s 8ms/step - loss: 0.0123 - accuracy: 0.9954 - precision: 0.9968 - recall: 0.9940 - val_loss: 1.6945 - val_accuracy: 0.8100 - val_precision: 0.7352 - val_recall: 0.9690\n","Epoch 78/100\n","313/313 [==============================] - 2s 8ms/step - loss: 0.0135 - accuracy: 0.9957 - precision: 0.9970 - recall: 0.9944 - val_loss: 1.2629 - val_accuracy: 0.8475 - val_precision: 0.7841 - val_recall: 0.9590\n","Epoch 79/100\n","313/313 [==============================] - 2s 8ms/step - loss: 0.0277 - accuracy: 0.9902 - precision: 0.9916 - recall: 0.9888 - val_loss: 1.6048 - val_accuracy: 0.8205 - val_precision: 0.7456 - val_recall: 0.9730\n","Epoch 80/100\n","313/313 [==============================] - 2s 8ms/step - loss: 0.0264 - accuracy: 0.9931 - precision: 0.9942 - recall: 0.9920 - val_loss: 1.4688 - val_accuracy: 0.8185 - val_precision: 0.7456 - val_recall: 0.9670\n","Epoch 81/100\n","313/313 [==============================] - 2s 8ms/step - loss: 0.0043 - accuracy: 0.9990 - precision: 0.9994 - recall: 0.9986 - val_loss: 2.1706 - val_accuracy: 0.7815 - val_precision: 0.7009 - val_recall: 0.9820\n","Epoch 82/100\n","313/313 [==============================] - 2s 8ms/step - loss: 0.0043 - accuracy: 0.9989 - precision: 0.9994 - recall: 0.9984 - val_loss: 1.6506 - val_accuracy: 0.8120 - val_precision: 0.7389 - val_recall: 0.9650\n","Epoch 83/100\n","313/313 [==============================] - 2s 8ms/step - loss: 0.0350 - accuracy: 0.9887 - precision: 0.9906 - recall: 0.9868 - val_loss: 1.0511 - val_accuracy: 0.8355 - val_precision: 0.7865 - val_recall: 0.9210\n","Epoch 84/100\n","313/313 [==============================] - 2s 8ms/step - loss: 0.0164 - accuracy: 0.9950 - precision: 0.9964 - recall: 0.9936 - val_loss: 1.6780 - val_accuracy: 0.8065 - val_precision: 0.7306 - val_recall: 0.9710\n","Epoch 85/100\n","313/313 [==============================] - 3s 8ms/step - loss: 0.0051 - accuracy: 0.9983 - precision: 0.9986 - recall: 0.9980 - val_loss: 1.4269 - val_accuracy: 0.8275 - val_precision: 0.7573 - val_recall: 0.9640\n","Epoch 86/100\n","313/313 [==============================] - 2s 8ms/step - loss: 0.0517 - accuracy: 0.9855 - precision: 0.9872 - recall: 0.9838 - val_loss: 1.1987 - val_accuracy: 0.8255 - val_precision: 0.7614 - val_recall: 0.9480\n","Epoch 87/100\n","313/313 [==============================] - 2s 8ms/step - loss: 0.0427 - accuracy: 0.9842 - precision: 0.9859 - recall: 0.9824 - val_loss: 1.7345 - val_accuracy: 0.7885 - val_precision: 0.7098 - val_recall: 0.9760\n","Epoch 88/100\n","313/313 [==============================] - 2s 8ms/step - loss: 0.0067 - accuracy: 0.9980 - precision: 0.9986 - recall: 0.9974 - val_loss: 1.5897 - val_accuracy: 0.8170 - val_precision: 0.7427 - val_recall: 0.9700\n","Epoch 89/100\n","313/313 [==============================] - 2s 8ms/step - loss: 0.0100 - accuracy: 0.9967 - precision: 0.9972 - recall: 0.9962 - val_loss: 1.4257 - val_accuracy: 0.8325 - val_precision: 0.7637 - val_recall: 0.9630\n","Epoch 90/100\n","313/313 [==============================] - 2s 8ms/step - loss: 0.0033 - accuracy: 0.9991 - precision: 0.9998 - recall: 0.9984 - val_loss: 2.3643 - val_accuracy: 0.7715 - val_precision: 0.6903 - val_recall: 0.9850\n","Epoch 91/100\n","313/313 [==============================] - 2s 8ms/step - loss: 0.0097 - accuracy: 0.9964 - precision: 0.9968 - recall: 0.9960 - val_loss: 1.4203 - val_accuracy: 0.8350 - val_precision: 0.7659 - val_recall: 0.9650\n","Epoch 92/100\n","313/313 [==============================] - 2s 8ms/step - loss: 0.0221 - accuracy: 0.9927 - precision: 0.9940 - recall: 0.9914 - val_loss: 1.8622 - val_accuracy: 0.7910 - val_precision: 0.7130 - val_recall: 0.9740\n","Epoch 93/100\n","313/313 [==============================] - 2s 8ms/step - loss: 0.0034 - accuracy: 0.9993 - precision: 0.9994 - recall: 0.9992 - val_loss: 1.8973 - val_accuracy: 0.7930 - val_precision: 0.7139 - val_recall: 0.9780\n","Epoch 94/100\n","313/313 [==============================] - 2s 8ms/step - loss: 0.0030 - accuracy: 0.9991 - precision: 0.9992 - recall: 0.9990 - val_loss: 1.4977 - val_accuracy: 0.8135 - val_precision: 0.7451 - val_recall: 0.9530\n","Epoch 95/100\n","313/313 [==============================] - 2s 8ms/step - loss: 0.0080 - accuracy: 0.9976 - precision: 0.9982 - recall: 0.9970 - val_loss: 1.0218 - val_accuracy: 0.8630 - val_precision: 0.8312 - val_recall: 0.9110\n","Epoch 96/100\n","313/313 [==============================] - 2s 8ms/step - loss: 0.0228 - accuracy: 0.9915 - precision: 0.9934 - recall: 0.9896 - val_loss: 1.2054 - val_accuracy: 0.8465 - val_precision: 0.7904 - val_recall: 0.9430\n","Epoch 97/100\n","313/313 [==============================] - 2s 8ms/step - loss: 0.0094 - accuracy: 0.9973 - precision: 0.9984 - recall: 0.9962 - val_loss: 1.4407 - val_accuracy: 0.8290 - val_precision: 0.7603 - val_recall: 0.9610\n","Epoch 98/100\n","313/313 [==============================] - 2s 8ms/step - loss: 0.0016 - accuracy: 0.9999 - precision: 1.0000 - recall: 0.9998 - val_loss: 1.7892 - val_accuracy: 0.8100 - val_precision: 0.7338 - val_recall: 0.9730\n","Epoch 99/100\n","313/313 [==============================] - 2s 8ms/step - loss: 0.0184 - accuracy: 0.9928 - precision: 0.9936 - recall: 0.9920 - val_loss: 1.3546 - val_accuracy: 0.8390 - val_precision: 0.7779 - val_recall: 0.9490\n","Epoch 100/100\n","313/313 [==============================] - 2s 8ms/step - loss: 0.0132 - accuracy: 0.9959 - precision: 0.9972 - recall: 0.9946 - val_loss: 1.3544 - val_accuracy: 0.8355 - val_precision: 0.7775 - val_recall: 0.9400\n"],"name":"stdout"},{"output_type":"execute_result","data":{"text/plain":["<tensorflow.python.keras.callbacks.History at 0x7f523b5834e0>"]},"metadata":{"tags":[]},"execution_count":9}]},{"cell_type":"code","metadata":{"id":"ujnIvww4bprh","colab_type":"code","colab":{}},"source":[""],"execution_count":null,"outputs":[]}]}